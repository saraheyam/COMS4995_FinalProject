{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import collections\n",
    "import pdb\n",
    "import torch.utils.data\n",
    "import csv\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def getlabel(c1,c2):\n",
    "    # get log fold change of expression\n",
    "\n",
    "    label1=math.log((float(c1)+1.0),2)\n",
    "    label2=math.log((float(c2)+1.0),2)\n",
    "    label=[]\n",
    "    label.append(label1)\n",
    "    label.append(label2)\n",
    "\n",
    "    fold_change=(float(c2)+1.0)/(float(c1)+1.0)\n",
    "    log_fold_change=math.log((fold_change),2)\n",
    "    return (log_fold_change, label)\n",
    "\n",
    "def loadDict(filename):\n",
    "    # get expression value of each gene from cell*.expr.csv\n",
    "    gene_dict={}\n",
    "    with open(filename) as fi:\n",
    "        for line in fi:\n",
    "            geneID,geneExpr=line.split(',')\n",
    "            gene_dict[str(geneID)]=float(geneExpr)\n",
    "    fi.close()\n",
    "    return(gene_dict)\n",
    "\n",
    "\n",
    "def loadData(filename,windows,gene_dict, num_hms):\n",
    "    \n",
    "    with open(filename) as fi:\n",
    "        csv_reader=csv.reader(fi)\n",
    "        data = list(csv_reader)\n",
    "    \n",
    "        ncols=(len(data[0]))\n",
    "    fi.close()\n",
    "\n",
    "    windows = 20\n",
    "    nrows=len(data)\n",
    "    ngenes=nrows/windows\n",
    "    nfeatures=ncols-1\n",
    "    \n",
    "    # testing args.n_hms vs nfeatures\n",
    "    if nfeatures != num_hms:\n",
    "        print(\"nfeatures != num_hms\")\n",
    "    assert(int(nfeatures) == int(num_hms))\n",
    "\n",
    "    \n",
    "    print(\"Number of genes: %d\" % ngenes)\n",
    "    print(\"Number of entries: %d\" % nrows)\n",
    "    print(\"Number of HMs: %d\" % nfeatures)\n",
    "\n",
    "    count = 0\n",
    "    attr = collections.OrderedDict()\n",
    "    alph = [chr(x) for x in range(ord('a'), ord('z') + 1)] # alphabetical key order more stable\n",
    "\n",
    "    gene_keys = [\"geneID\", \"expr\"]\n",
    "    hm_id = [\"hm_\" + alph[i] for i in list(range(nfeatures))]\n",
    "    data_mat = np.array(data)\n",
    "\n",
    "    for i in range(0, nrows, windows):\n",
    "        geneID=str(data[i][0].split(\"_\")[0])\n",
    "    \n",
    "        meta = {}\n",
    "        meta[\"geneID\"] = geneID\n",
    "        meta[\"expr\"] = gene_dict[geneID]\n",
    "    \n",
    "        for j in range(nfeatures):\n",
    "            meta[hm_id[j]] = torch.tensor(np.array([float(z) for z in data_mat[i:(i+windows), j+1]]).reshape(windows, 1))\n",
    "    \n",
    "        attr[count] = meta\n",
    "        count+=1    \n",
    "        \n",
    "    return attr\n",
    "\n",
    "#### NEED TO EDIT THIS TO TAKE N-FEATURES\n",
    "\n",
    "class HMData(Dataset):\n",
    "    # Dataset class for loading data\n",
    "    def __init__(self,data_cell1,data_cell2, n_feat, transform = None): \n",
    "        self.c1=data_cell1\n",
    "        self.c2=data_cell2\n",
    "        self.nfeat = n_feat\n",
    "        assert (len(self.c1)==len(self.c2))\n",
    "    def __len__(self):\n",
    "        return len(self.c1)\n",
    "    def __getitem__(self,i):\n",
    "                 \n",
    "        alph = [chr(x) for x in range(ord('a'), ord('z') + 1)]\n",
    "        hm_id = [\"hm_\" + alph[y] for y in list(range(self.nfeat))]\n",
    "                 \n",
    "#         final_data_c1=torch.cat((self.c1[i]['hm1'],self.c1[i]['hm2'],self.c1[i]['hm3'],self.c1[i]['hm4'],self.c1[i]['hm5']),1)\n",
    "#         final_data_c2=torch.cat((self.c2[i]['hm1'],self.c2[i]['hm2'],self.c2[i]['hm3'],self.c2[i]['hm4'],self.c2[i]['hm5']),1)\n",
    "        \n",
    "        final_data_c1 = torch.cat([self.c1[i][z] for z in hm_id], 1) \n",
    "        final_data_c2 = torch.cat([self.c2[i][w] for w in hm_id], 1)         \n",
    "                \n",
    "        label,orig_label=getlabel(self.c1[i]['expr'],self.c2[i]['expr'])\n",
    "        b_label_c1=orig_label[0]\n",
    "        b_label_c2=orig_label[1]\n",
    "        assert self.c1[i]['geneID']==self.c2[i]['geneID']\n",
    "        geneID=self.c1[i]['geneID']\n",
    "        sample={'geneID':geneID,\n",
    "               'X_A':final_data_c1,\n",
    "               'X_B':final_data_c2,\n",
    "               'diff':label,\n",
    "               'abs_A':b_label_c1,'abs_B':b_label_c2}\n",
    "        return sample\n",
    "    \n",
    "### NEED TO PASS args.n_hms TO HMDATA FOR nfeat ARGUMENT    \n",
    "#  assert that nfeatures == args.n_hms\n",
    "#  could also just pass nfeatures from loadData (still needs assert)\n",
    "\n",
    "def load_data(args):\n",
    "    '''\n",
    "    Loads data into a 3D tensor for each of the 3 splits.\n",
    "\n",
    "    '''\n",
    "    print(\"==>loading train data\")\n",
    "    gene_dict1=loadDict(args.data_root+args.cell_1+\".expr.csv\")\n",
    "    gene_dict2=loadDict(args.data_root+args.cell_2+\".expr.csv\")\n",
    "    \n",
    "    cell_train_dict1=loadData(args.data_root+\"/\"+args.cell_1+\".train.csv\",\n",
    "                              args.n_bins,gene_dict1, args.n_hms) # n_hms assert    \n",
    "    cell_train_dict2=loadData(args.data_root+\"/\"+args.cell_2+\".train.csv\",\n",
    "                              args.n_bins,gene_dict2, args.n_hms) # n_hms assert\n",
    "    train_inputs = HMData(cell_train_dict1,cell_train_dict2, args.n_hms) # added dynamic args.n_hms \n",
    "    \n",
    "    print(\"==>loading valid data\")\n",
    "    cell_valid_dict1=loadData(args.data_root+\"/\"+args.cell_1+\".valid.csv\", \n",
    "                              args.n_bins,gene_dict1, args.n_hms) \n",
    "    cell_valid_dict2=loadData(args.data_root+\"/\"+args.cell_2+\".valid.csv\", \n",
    "                              args.n_bins,gene_dict2, args.n_hms)   \n",
    "    valid_inputs = HMData(cell_valid_dict1,cell_valid_dict2, args.n_hms) \n",
    "    \n",
    "    print(\"==>loading test data\")\n",
    "    cell_test_dict1=loadData(args.data_root+\"/\"+args.cell_1+\".test.csv\", \n",
    "                             args.n_bins,gene_dict1, args.n_hms) \n",
    "    cell_test_dict2=loadData(args.data_root+\"/\"+args.cell_2+\".test.csv\", \n",
    "                             args.n_bins,gene_dict2, args.n_hms)   \n",
    "    test_inputs = HMData(cell_test_dict1,cell_test_dict2, args.n_hms)\n",
    "\n",
    "\n",
    "    Train = torch.utils.data.DataLoader(train_inputs, batch_size=args.batch_size, shuffle=True)\n",
    "    Valid = torch.utils.data.DataLoader(valid_inputs, batch_size=args.batch_size, shuffle=False)\n",
    "    Test = torch.utils.data.DataLoader(test_inputs, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    return Train,Valid,Test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "data_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
